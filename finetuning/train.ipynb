{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing all the necessary libraries",
   "id": "90e561b4198812d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:50:47.826622Z",
     "start_time": "2025-01-09T19:50:41.278608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# basic libraries\n",
    "import copy\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "from lib2to3.pgen2.tokenize import tokenize\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "\n",
    "# libraries for the model training and dataset loading\n",
    "from datasets import load_dataset\n",
    "from keras.src.metrics.accuracy_metrics import accuracy\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# LoRA library from Microsoft (https://github.com/microsoft/LoRA/tree/main)\n",
    "import loralib\n",
    "\n",
    "# files with custom Bert model and the changed file from transformers library\n",
    "import bert_multi_lora\n",
    "from custom_model import CustomBert, LoRABert"
   ],
   "id": "c2bb9895b2c58ab5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balanton\\AppData\\Local\\Temp\\ipykernel_10844\\1634781091.py:6: DeprecationWarning: lib2to3 package is deprecated and may not be able to parse Python 3.10+\n",
      "  from lib2to3.pgen2.tokenize import tokenize\n",
      "C:\\Users\\balanton\\anaconda3\\envs\\semester_project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:50:47.831875Z",
     "start_time": "2025-01-09T19:50:47.829629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# uncomment the below line if you want to automatically reload the modules\n",
    "# though this will disable debugging in the notebook\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ],
   "id": "f1c8fef1b7a46e9a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:50:47.999590Z",
     "start_time": "2025-01-09T19:50:47.951744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setting device to `cuda` if gpu exists\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ],
   "id": "98987abe7c4dd973",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:50:49.070656Z",
     "start_time": "2025-01-09T19:50:48.006712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "# model is initialized from the custom file since it has the masking functionality\n",
    "bert = bert_multi_lora.BertModel.from_pretrained(model_name, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "id": "ed62fdabe1b22d40",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Custom model finetuning",
   "id": "d826b612f2f73587"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset and Dataloaders",
   "id": "14326802516b9b43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:50:49.084616Z",
     "start_time": "2025-01-09T19:50:49.079618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiAdapterDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for the custom dataset that will be used for training and evaluation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, datasets, lora_cnt=2, id=None):\n",
    "        \"\"\"\n",
    "        Constructor for the class.\n",
    "        \n",
    "        :param datasets: datasets that will be used to train and evaluate respective adapters\n",
    "        :param lora_cnt: number of adapters\n",
    "        :param id: id of the adapter (& dataset) that will be used for the evaluation. If None, the dataset is used for training\n",
    "        \"\"\"\n",
    "        self.datasets = datasets\n",
    "        self.id = id\n",
    "        self.lora_cnt = lora_cnt\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Function to get the length of the dataset.\n",
    "        \n",
    "        :return: length of the dataset. If id is not None, the length of the dataset with the given id is returned, otherwise the sum of the lengths of all datasets is returned\n",
    "        \"\"\"\n",
    "        if self.id is not None:\n",
    "            return len(self.datasets[0])\n",
    "        else:\n",
    "            return sum([len(d) for d in self.datasets])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Function to get the item from the dataset.\n",
    "        \n",
    "        :param idx: index of the item\n",
    "        :return: item from the dataset. If id is not None, the item from the dataset with the given id is returned, otherwise the item from the dataset with the index (idx % lora_cnt) is returned\n",
    "        \"\"\"\n",
    "        \n",
    "        # masking is used to determine which adapter is used for the given item, it is 1 for the adapter that is used and 0 for the other adapters\n",
    "        masking = torch.zeros(self.lora_cnt)\n",
    "        \n",
    "        if self.id is not None: \n",
    "            masking[self.id] = 1\n",
    "            d = self.datasets[0][idx]\n",
    "        else:\n",
    "            masking[idx % self.lora_cnt] = 1\n",
    "            d = self.datasets[idx % self.lora_cnt][idx // self.lora_cnt]\n",
    "        \n",
    "        ids = torch.tensor(d['input_ids'])\n",
    "        mask = torch.tensor(d['attention_mask'])\n",
    "        label = torch.tensor(d['label'])\n",
    "        \n",
    "        return ids, mask, label, masking"
   ],
   "id": "4fe74418a8e100b6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:50:49.098066Z",
     "start_time": "2025-01-09T19:50:49.093028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# here we define the tokenization functions for the datasets, different functions are used for different datasets as the structure of the datasets is different\n",
    "def tokenize_imdb(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "def tokenize_rotten_tomatoes(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "def tokenize_amazon(examples):\n",
    "    return tokenizer(examples[\"content\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "\n",
    "def get_tokenized_datasets(paths, functions, split=\"train\", batched=True, num_samples=1000):\n",
    "    \"\"\"\n",
    "    Function to get the tokenized datasets.\n",
    "    \n",
    "    :param paths: paths to the datasets, can be local paths or the names of the datasets from the Hugging Face library\n",
    "    :param functions: functions that will be used to tokenize the datasets\n",
    "    :param split: split of the dataset that will be used, can be \"train\" or \"test\"\n",
    "    :param batched: whether the tokenization should be batched\n",
    "    :param num_samples: number of samples that will be used from each dataset\n",
    "    :return: list of tokenized datasets\n",
    "    \"\"\"\n",
    "    datasets = [load_dataset(path) for path in paths]\n",
    "    tokenized_datasets = [dataset.map(function, batched=batched)[split].shuffle(seed=42).select(range(num_samples)) for dataset, function in zip(datasets, functions)]\n",
    "    return tokenized_datasets\n",
    "\n",
    "def get_dataloaders(tokenized_datasets, lora_cnt, split=\"train\", batch_size=16):\n",
    "    \"\"\"\n",
    "    Function to get the dataloaders for the datasets.\n",
    "    \n",
    "    :param tokenized_datasets: tokenized datasets\n",
    "    :param lora_cnt: number of adapters\n",
    "    :param split: split of the dataset that will be used, can be \"train\" or \"test\"\n",
    "    :param batch_size: batch size\n",
    "    :return: list of dataloaders\n",
    "    \"\"\"\n",
    "    # if the split is \"train\", only one dataloader is returned, otherwise a list of dataloaders is returned\n",
    "    if split==\"train\":\n",
    "        dataset = MultiAdapterDataset(tokenized_datasets, lora_cnt=lora_cnt)\n",
    "        return DataLoader(dataset, shuffle=False, batch_size=batch_size)\n",
    "    elif split==\"test\":\n",
    "        datasets = [MultiAdapterDataset([tokenized_datasets[i]], lora_cnt=lora_cnt, id=i) for i in range(lora_cnt)]\n",
    "        return [DataLoader(dataset, shuffle=False, batch_size=batch_size) for dataset in datasets]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid split\")"
   ],
   "id": "d49b3bd8a75d6467",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:50:49.109278Z",
     "start_time": "2025-01-09T19:50:49.106339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = [\"imdb\", \"fancyzhx/amazon_polarity\", \"cornell-movie-review-data/rotten_tomatoes\"]\n",
    "functions = [tokenize_imdb, tokenize_amazon, tokenize_rotten_tomatoes]"
   ],
   "id": "e3895193d6317c65",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Defining the model",
   "id": "e251b84e0f5a8d8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:50:49.375059Z",
     "start_time": "2025-01-09T19:50:49.117544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define LoRA parameters\n",
    "num_adapters = len(datasets)\n",
    "num_samples = 1024\n",
    "rank = 8\n",
    "alpha = 8\n",
    "\n",
    "# Initialize the custom model\n",
    "model = CustomBert(copy.deepcopy(bert), num_adapters=num_adapters, rank=rank, alpha=alpha).to(device)"
   ],
   "id": "969a7ac709b4458e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initial evaluation",
   "id": "c57745f30a538c2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:51:01.509500Z",
     "start_time": "2025-01-09T19:50:49.385919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_test = get_tokenized_datasets(datasets, functions, num_samples=num_samples, split=\"test\")\n",
    "\n",
    "test_loaders = get_dataloaders(tokenized_test, num_adapters, split=\"test\")"
   ],
   "id": "845d0b93966bbf02",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:51:13.690615Z",
     "start_time": "2025-01-09T19:51:01.519299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate both adapters on respective datasets\n",
    "model.eval()\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "for i in range(num_adapters):\n",
    "    total_loss = 0\n",
    "    for batch in test_loaders[i]:\n",
    "        ids, masks, labels, masking = batch\n",
    "        labels = labels.type(torch.float)\n",
    "        o = model(ids.to(device), masks.to(device), masking.to(device))\n",
    "        loss = criterion(torch.squeeze(o), labels.to(device))\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Adapter {i} loss: {total_loss / len(test_loaders[i])}\")"
   ],
   "id": "b8182de951464ffa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter 0 loss: 0.698785443790257\n",
      "Adapter 1 loss: 0.7059074295684695\n",
      "Adapter 2 loss: 0.7004719730466604\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "aa1b010fabc8010c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:51:23.123685Z",
     "start_time": "2025-01-09T19:51:13.729898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_datasets = get_tokenized_datasets(datasets, functions, num_samples=num_samples, split=\"train\")\n",
    "\n",
    "train_dataloader = get_dataloaders(tokenized_datasets, num_adapters, split=\"train\")"
   ],
   "id": "73b09760f777e380",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:51:23.168455Z",
     "start_time": "2025-01-09T19:51:23.162452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Mark only LoRA parameters as trainable\n",
    "for name, param in model.named_parameters():\n",
    "    if \"adapter\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6, weight_decay=0)\n",
    "\n",
    "num_epochs = 50\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ],
   "id": "a9ed8f83e593f02a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:51:23.213272Z",
     "start_time": "2025-01-09T19:51:23.207233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.requires_grad)"
   ],
   "id": "64aaeb79220553c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.encoder.layer.0.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.0.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.0.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.0.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.0.attention.self.query.adapters.2.lora_A True\n",
      "bert.encoder.layer.0.attention.self.query.adapters.2.lora_B True\n",
      "bert.encoder.layer.0.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.0.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.0.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.0.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.0.attention.self.key.adapters.2.lora_A True\n",
      "bert.encoder.layer.0.attention.self.key.adapters.2.lora_B True\n",
      "bert.encoder.layer.0.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.0.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.0.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.0.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.0.attention.self.value.adapters.2.lora_A True\n",
      "bert.encoder.layer.0.attention.self.value.adapters.2.lora_B True\n",
      "bert.encoder.layer.1.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.1.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.1.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.1.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.1.attention.self.query.adapters.2.lora_A True\n",
      "bert.encoder.layer.1.attention.self.query.adapters.2.lora_B True\n",
      "bert.encoder.layer.1.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.1.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.1.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.1.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.1.attention.self.key.adapters.2.lora_A True\n",
      "bert.encoder.layer.1.attention.self.key.adapters.2.lora_B True\n",
      "bert.encoder.layer.1.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.1.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.1.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.1.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.1.attention.self.value.adapters.2.lora_A True\n",
      "bert.encoder.layer.1.attention.self.value.adapters.2.lora_B True\n",
      "bert.encoder.layer.2.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.2.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.2.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.2.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.2.attention.self.query.adapters.2.lora_A True\n",
      "bert.encoder.layer.2.attention.self.query.adapters.2.lora_B True\n",
      "bert.encoder.layer.2.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.2.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.2.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.2.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.2.attention.self.key.adapters.2.lora_A True\n",
      "bert.encoder.layer.2.attention.self.key.adapters.2.lora_B True\n",
      "bert.encoder.layer.2.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.2.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.2.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.2.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.2.attention.self.value.adapters.2.lora_A True\n",
      "bert.encoder.layer.2.attention.self.value.adapters.2.lora_B True\n",
      "bert.encoder.layer.3.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.3.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.3.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.3.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.3.attention.self.query.adapters.2.lora_A True\n",
      "bert.encoder.layer.3.attention.self.query.adapters.2.lora_B True\n",
      "bert.encoder.layer.3.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.3.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.3.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.3.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.3.attention.self.key.adapters.2.lora_A True\n",
      "bert.encoder.layer.3.attention.self.key.adapters.2.lora_B True\n",
      "bert.encoder.layer.3.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.3.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.3.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.3.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.3.attention.self.value.adapters.2.lora_A True\n",
      "bert.encoder.layer.3.attention.self.value.adapters.2.lora_B True\n",
      "bert.encoder.layer.4.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.4.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.4.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.4.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.4.attention.self.query.adapters.2.lora_A True\n",
      "bert.encoder.layer.4.attention.self.query.adapters.2.lora_B True\n",
      "bert.encoder.layer.4.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.4.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.4.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.4.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.4.attention.self.key.adapters.2.lora_A True\n",
      "bert.encoder.layer.4.attention.self.key.adapters.2.lora_B True\n",
      "bert.encoder.layer.4.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.4.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.4.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.4.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.4.attention.self.value.adapters.2.lora_A True\n",
      "bert.encoder.layer.4.attention.self.value.adapters.2.lora_B True\n",
      "bert.encoder.layer.5.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.5.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.5.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.5.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.5.attention.self.query.adapters.2.lora_A True\n",
      "bert.encoder.layer.5.attention.self.query.adapters.2.lora_B True\n",
      "bert.encoder.layer.5.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.5.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.5.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.5.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.5.attention.self.key.adapters.2.lora_A True\n",
      "bert.encoder.layer.5.attention.self.key.adapters.2.lora_B True\n",
      "bert.encoder.layer.5.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.5.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.5.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.5.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.5.attention.self.value.adapters.2.lora_A True\n",
      "bert.encoder.layer.5.attention.self.value.adapters.2.lora_B True\n",
      "bert.encoder.layer.6.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.6.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.6.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.6.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.6.attention.self.query.adapters.2.lora_A True\n",
      "bert.encoder.layer.6.attention.self.query.adapters.2.lora_B True\n",
      "bert.encoder.layer.6.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.6.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.6.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.6.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.6.attention.self.key.adapters.2.lora_A True\n",
      "bert.encoder.layer.6.attention.self.key.adapters.2.lora_B True\n",
      "bert.encoder.layer.6.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.6.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.6.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.6.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.6.attention.self.value.adapters.2.lora_A True\n",
      "bert.encoder.layer.6.attention.self.value.adapters.2.lora_B True\n",
      "bert.encoder.layer.7.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.7.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.7.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.7.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.7.attention.self.query.adapters.2.lora_A True\n",
      "bert.encoder.layer.7.attention.self.query.adapters.2.lora_B True\n",
      "bert.encoder.layer.7.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.7.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.7.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.7.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.7.attention.self.key.adapters.2.lora_A True\n",
      "bert.encoder.layer.7.attention.self.key.adapters.2.lora_B True\n",
      "bert.encoder.layer.7.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.7.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.7.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.7.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.7.attention.self.value.adapters.2.lora_A True\n",
      "bert.encoder.layer.7.attention.self.value.adapters.2.lora_B True\n",
      "bert.encoder.layer.8.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.8.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.8.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.8.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.8.attention.self.query.adapters.2.lora_A True\n",
      "bert.encoder.layer.8.attention.self.query.adapters.2.lora_B True\n",
      "bert.encoder.layer.8.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.8.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.8.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.8.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.8.attention.self.key.adapters.2.lora_A True\n",
      "bert.encoder.layer.8.attention.self.key.adapters.2.lora_B True\n",
      "bert.encoder.layer.8.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.8.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.8.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.8.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.8.attention.self.value.adapters.2.lora_A True\n",
      "bert.encoder.layer.8.attention.self.value.adapters.2.lora_B True\n",
      "bert.encoder.layer.9.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.9.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.9.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.9.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.9.attention.self.query.adapters.2.lora_A True\n",
      "bert.encoder.layer.9.attention.self.query.adapters.2.lora_B True\n",
      "bert.encoder.layer.9.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.9.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.9.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.9.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.9.attention.self.key.adapters.2.lora_A True\n",
      "bert.encoder.layer.9.attention.self.key.adapters.2.lora_B True\n",
      "bert.encoder.layer.9.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.9.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.9.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.9.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.9.attention.self.value.adapters.2.lora_A True\n",
      "bert.encoder.layer.9.attention.self.value.adapters.2.lora_B True\n",
      "bert.encoder.layer.10.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.10.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.10.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.10.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.10.attention.self.query.adapters.2.lora_A True\n",
      "bert.encoder.layer.10.attention.self.query.adapters.2.lora_B True\n",
      "bert.encoder.layer.10.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.10.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.10.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.10.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.10.attention.self.key.adapters.2.lora_A True\n",
      "bert.encoder.layer.10.attention.self.key.adapters.2.lora_B True\n",
      "bert.encoder.layer.10.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.10.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.10.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.10.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.10.attention.self.value.adapters.2.lora_A True\n",
      "bert.encoder.layer.10.attention.self.value.adapters.2.lora_B True\n",
      "bert.encoder.layer.11.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.11.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.11.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.11.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.11.attention.self.query.adapters.2.lora_A True\n",
      "bert.encoder.layer.11.attention.self.query.adapters.2.lora_B True\n",
      "bert.encoder.layer.11.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.11.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.11.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.11.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.11.attention.self.key.adapters.2.lora_A True\n",
      "bert.encoder.layer.11.attention.self.key.adapters.2.lora_B True\n",
      "bert.encoder.layer.11.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.11.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.11.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.11.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.11.attention.self.value.adapters.2.lora_A True\n",
      "bert.encoder.layer.11.attention.self.value.adapters.2.lora_B True\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:51:23.320814Z",
     "start_time": "2025-01-09T19:51:23.316757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(data):\n",
    "    ids, masks, labels, masking = data\n",
    "    labels = labels.type(torch.float)\n",
    "\n",
    "    o = model(ids.to(device), masks.to(device), masking.to(device)) \n",
    "\n",
    "    loss = criterion(torch.squeeze(o), labels.to(device))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()  \n",
    "    lr_scheduler.step()"
   ],
   "id": "5899cb3de58b2c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:13:09.998420Z",
     "start_time": "2025-01-09T19:51:23.364339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in tqdm.tqdm(range(num_epochs), desc=\"Training\"):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, batch in enumerate(train_dataloader):    \n",
    "        ids, masks, labels, masking = batch\n",
    "        labels = labels.type(torch.float).to(device)\n",
    "    \n",
    "        o = model(ids.to(device), masks.to(device), masking.to(device)) \n",
    "    \n",
    "        loss = criterion(torch.squeeze(o), labels)\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()  \n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    losses.append(running_loss / len(train_dataloader))\n",
    "        \n",
    "print(f\"Training time: {time.time() - start}\")"
   ],
   "id": "c7d9f0847d3ee7b9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [21:46<00:00, 26.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1306.630577325821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:13:10.304412Z",
     "start_time": "2025-01-09T20:13:10.218819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ],
   "id": "b01e5ad1f0ba9948",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "fd56ff8227d9da28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:13:22.392622Z",
     "start_time": "2025-01-09T20:13:10.319814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate both adapters on respective datasets\n",
    "model.eval()\n",
    "\n",
    "for i in range(num_adapters):\n",
    "    total_loss = 0\n",
    "    for batch in test_loaders[i]:\n",
    "        ids, masks, labels, masking = batch\n",
    "        labels = labels.type(torch.float)\n",
    "        o = model(ids.to(device), masks.to(device), masking.to(device))\n",
    "        # o = model(ids.to(device), masks.to(device), torch.tensor(i).to(device))\n",
    "        loss = criterion(torch.squeeze(o), labels.to(device))\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Adapter {i} loss: {total_loss / len(test_loaders[i])}\")"
   ],
   "id": "2a207c2e0e21ea88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter 0 loss: 0.5022003222256899\n",
      "Adapter 1 loss: 0.3347455847542733\n",
      "Adapter 2 loss: 0.4473282548133284\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving the model",
   "id": "f179764673983a33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:43:31.875720Z",
     "start_time": "2025-01-09T19:43:31.873199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save the tokenizer and the model in `./test-model/` directory \n",
    "# tokenizer.save_pretrained(\"./test-model/\")\n",
    "# model.save_pretrained(\"./test-model/\", push_to_hub=False)"
   ],
   "id": "c8180afd14c3f9c8",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LoRA model finetuning",
   "id": "ba62b50435faa201"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:43:33.757005Z",
     "start_time": "2025-01-09T19:43:31.890742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_adapters = len(datasets)\n",
    "\n",
    "bert_normal = AutoModel.from_pretrained(model_name, device_map=\"auto\")\n",
    "loraBerts = [LoRABert(copy.deepcopy(bert_normal)).to(device) for _ in range(num_adapters)]\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Mark only LoRA parameters as trainable\n",
    "for i in range(num_adapters):\n",
    "    for name, param in loraBerts[i].named_parameters():\n",
    "        if \"lora\" in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False"
   ],
   "id": "4dd2ebc0f50e7ede",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initial evaluation",
   "id": "46d78de3f9d75f9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:43:53.299418Z",
     "start_time": "2025-01-09T19:43:33.775773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_test = get_tokenized_datasets(datasets, functions, num_samples=num_samples, split=\"test\")\n",
    "\n",
    "test_loaders = get_dataloaders(tokenized_test, num_adapters, split=\"test\")\n",
    "\n",
    "for i in range(num_adapters):\n",
    "    loraBerts[i].eval()\n",
    "    total_loss = 0\n",
    "    for batch in test_loaders[i]:\n",
    "        ids, masks, labels, _ = batch\n",
    "        labels = labels.type(torch.float)\n",
    "        o = loraBerts[i](ids.to(device), masks.to(device))\n",
    "        loss = criterion(torch.squeeze(o), labels.to(device))\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Adapter {i} loss: {total_loss / len(test_loaders[i])}\")"
   ],
   "id": "4a7c939eaf8897b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter 0 loss: 0.6931545687839389\n",
      "Adapter 1 loss: 0.6981197809800506\n",
      "Adapter 2 loss: 0.6902256393805146\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "7d23dda9ce39883c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:44:02.653767Z",
     "start_time": "2025-01-09T19:43:53.317660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "for i in range(num_adapters):\n",
    "    loraBerts[i].train()\n",
    "    \n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "tokenized_datasets = get_tokenized_datasets(datasets, functions, num_samples=num_samples, split=\"train\")\n",
    "train_dataloaders = get_dataloaders(tokenized_datasets, num_adapters, split=\"test\")\n",
    "\n",
    "num_epochs = num_epochs\n",
    "optimizers = [AdamW(loraBerts[i].parameters(), lr=5e-6, weight_decay=0) for i in range(num_adapters)]\n",
    "num_training_steps = [num_epochs * len(train_dataloaders[i]) for i in range(num_adapters)]\n",
    "lr_schedulers = [get_scheduler(\"linear\", optimizer=optimizers[i], num_warmup_steps=0, num_training_steps=num_training_steps[i]) for i in range(num_adapters)]"
   ],
   "id": "5e7c93db0d7c0407",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:47:37.161633Z",
     "start_time": "2025-01-09T19:44:02.706100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(num_adapters):\n",
    "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "        for batch in train_dataloaders[i]:\n",
    "            ids, masks, labels, _ = batch\n",
    "            labels = labels.type(torch.float)\n",
    "            o = loraBerts[i](ids.to(device), masks.to(device))\n",
    "\n",
    "            loss = criterion(torch.squeeze(o), labels.to(device))\n",
    "            loss.backward()\n",
    "\n",
    "            optimizers[i].step()\n",
    "            optimizers[i].zero_grad()\n",
    "            lr_schedulers[i].step()\n",
    "\n",
    "print(f\"Training time: {time.time() - start}\")"
   ],
   "id": "63b57563e03812a5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:12<00:00,  7.24s/it]\n",
      "100%|██████████| 10/10 [01:12<00:00,  7.21s/it]\n",
      "100%|██████████| 10/10 [01:09<00:00,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 214.45205950737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "feb1688690b914f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:47:47.149230Z",
     "start_time": "2025-01-09T19:47:37.332052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(num_adapters):\n",
    "    loraBerts[i].eval()\n",
    "    total_loss = 0\n",
    "    for batch in test_loaders[i]:\n",
    "        ids, masks, labels, _ = batch\n",
    "        labels = labels.type(torch.float)\n",
    "        o = loraBerts[i](ids.to(device), masks.to(device))\n",
    "        loss = criterion(torch.squeeze(o), labels.to(device))\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Adapter {i} loss: {total_loss / len(test_loaders[i])}\")"
   ],
   "id": "c3244a28ed8d827f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter 0 loss: 0.6923950416967273\n",
      "Adapter 1 loss: 0.696713755838573\n",
      "Adapter 2 loss: 0.6894992822781205\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
