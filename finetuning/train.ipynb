{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing all the necessary libraries",
   "id": "90e561b4198812d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:17:04.487180Z",
     "start_time": "2025-01-08T20:16:58.834329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# basic libraries\n",
    "import copy\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "from lib2to3.pgen2.tokenize import tokenize\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "\n",
    "# libraries for the model training and dataset loading\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# LoRA library from Microsoft (https://github.com/microsoft/LoRA/tree/main)\n",
    "import loralib\n",
    "\n",
    "# files with custom Bert model and the changed file from transformers library\n",
    "import bert_multi_lora\n",
    "from custom_model import CustomBert, LoRABert"
   ],
   "id": "c2bb9895b2c58ab5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balanton\\AppData\\Local\\Temp\\ipykernel_28448\\1978751123.py:6: DeprecationWarning: lib2to3 package is deprecated and may not be able to parse Python 3.10+\n",
      "  from lib2to3.pgen2.tokenize import tokenize\n",
      "C:\\Users\\balanton\\anaconda3\\envs\\semester_project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:17:04.495325Z",
     "start_time": "2025-01-08T20:17:04.490713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# uncomment the below line if you want to automatically reload the modules\n",
    "# though this will disable debugging in the notebook\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ],
   "id": "f1c8fef1b7a46e9a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:17:04.773786Z",
     "start_time": "2025-01-08T20:17:04.728912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setting device to `cuda` if gpu exists\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ],
   "id": "98987abe7c4dd973",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:17:05.829917Z",
     "start_time": "2025-01-08T20:17:04.790539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "# model is initialized from the custom file since it has the masking functionality\n",
    "bert = bert_multi_lora.BertModel.from_pretrained(model_name, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "id": "ed62fdabe1b22d40",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Custom model finetuning",
   "id": "d826b612f2f73587"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset and Dataloaders",
   "id": "14326802516b9b43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:17:11.462965Z",
     "start_time": "2025-01-08T20:17:11.457600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiAdapterDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for the custom dataset that will be used for training and evaluation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, datasets, lora_cnt=2, id=None):\n",
    "        \"\"\"\n",
    "        Constructor for the class.\n",
    "        \n",
    "        :param datasets: datasets that will be used to train and evaluate respective adapters\n",
    "        :param lora_cnt: number of adapters\n",
    "        :param id: id of the adapter (& dataset) that will be used for the evaluation. If None, the dataset is used for training\n",
    "        \"\"\"\n",
    "        self.datasets = datasets\n",
    "        self.id = id\n",
    "        self.lora_cnt = lora_cnt\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Function to get the length of the dataset.\n",
    "        \n",
    "        :return: length of the dataset. If id is not None, the length of the dataset with the given id is returned, otherwise the sum of the lengths of all datasets is returned\n",
    "        \"\"\"\n",
    "        if self.id is not None:\n",
    "            return len(self.datasets[0])\n",
    "        else:\n",
    "            return sum([len(d) for d in self.datasets])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Function to get the item from the dataset.\n",
    "        \n",
    "        :param idx: index of the item\n",
    "        :return: item from the dataset. If id is not None, the item from the dataset with the given id is returned, otherwise the item from the dataset with the index (idx % lora_cnt) is returned\n",
    "        \"\"\"\n",
    "        \n",
    "        # masking is used to determine which adapter is used for the given item, it is 1 for the adapter that is used and 0 for the other adapters\n",
    "        masking = torch.zeros(self.lora_cnt)\n",
    "        \n",
    "        if self.id is not None: \n",
    "            masking[self.id] = 1\n",
    "            d = self.datasets[0][idx]\n",
    "        else:\n",
    "            masking[idx % self.lora_cnt] = 1\n",
    "            d = self.datasets[idx % self.lora_cnt][idx // self.lora_cnt]\n",
    "        \n",
    "        ids = torch.tensor(d['input_ids'])\n",
    "        mask = torch.tensor(d['attention_mask'])\n",
    "        label = torch.tensor(d['label'])\n",
    "        \n",
    "        return ids, mask, label, masking"
   ],
   "id": "4fe74418a8e100b6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:17:11.491444Z",
     "start_time": "2025-01-08T20:17:11.484594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# here we define the tokenization functions for the datasets, different functions are used for different datasets as the structure of the datasets is different\n",
    "def tokenize_imdb(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "def tokenize_sst2(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "def tokenize_amazon(examples):\n",
    "    return tokenizer(examples[\"content\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "\n",
    "def get_tokenized_datasets(paths, functions, split=\"train\", batched=True, num_samples=1000):\n",
    "    \"\"\"\n",
    "    Function to get the tokenized datasets.\n",
    "    \n",
    "    :param paths: paths to the datasets, can be local paths or the names of the datasets from the Hugging Face library\n",
    "    :param functions: functions that will be used to tokenize the datasets\n",
    "    :param split: split of the dataset that will be used, can be \"train\" or \"test\"\n",
    "    :param batched: whether the tokenization should be batched\n",
    "    :param num_samples: number of samples that will be used from each dataset\n",
    "    :return: list of tokenized datasets\n",
    "    \"\"\"\n",
    "    datasets = [load_dataset(path) for path in paths]\n",
    "    tokenized_datasets = [dataset.map(function, batched=batched)[split].shuffle(seed=42).select(range(num_samples)) for dataset, function in zip(datasets, functions)]\n",
    "    return tokenized_datasets\n",
    "\n",
    "def get_dataloaders(tokenized_datasets, lora_cnt, split=\"train\", batch_size=16):\n",
    "    \"\"\"\n",
    "    Function to get the dataloaders for the datasets.\n",
    "    \n",
    "    :param tokenized_datasets: tokenized datasets\n",
    "    :param lora_cnt: number of adapters\n",
    "    :param split: split of the dataset that will be used, can be \"train\" or \"test\"\n",
    "    :param batch_size: batch size\n",
    "    :return: list of dataloaders\n",
    "    \"\"\"\n",
    "    # if the split is \"train\", only one dataloader is returned, otherwise a list of dataloaders is returned\n",
    "    if split==\"train\":\n",
    "        dataset = MultiAdapterDataset(tokenized_datasets, lora_cnt=lora_cnt)\n",
    "        return DataLoader(dataset, shuffle=False, batch_size=batch_size)\n",
    "    elif split==\"test\":\n",
    "        datasets = [MultiAdapterDataset([tokenized_datasets[i]], lora_cnt=lora_cnt, id=i) for i in range(lora_cnt)]\n",
    "        return [DataLoader(dataset, shuffle=False, batch_size=batch_size) for dataset in datasets]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid split\")"
   ],
   "id": "d49b3bd8a75d6467",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Defining the model",
   "id": "e251b84e0f5a8d8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T19:43:08.628829Z",
     "start_time": "2025-01-08T19:43:08.349154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define LoRA parameters\n",
    "num_adapters = 2\n",
    "rank = 8\n",
    "alpha = 32\n",
    "\n",
    "# Initialize the custom model\n",
    "model = CustomBert(copy.deepcopy(bert), num_adapters=num_adapters, rank=rank, alpha=alpha).to(device)"
   ],
   "id": "969a7ac709b4458e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initial evaluation",
   "id": "c57745f30a538c2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T19:46:58.967024Z",
     "start_time": "2025-01-08T19:43:08.631860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_test = get_tokenized_datasets([\"imdb\", \"fancyzhx/amazon_polarity\"], [tokenize_imdb, tokenize_amazon], num_samples=1000, split=\"test\")\n",
    "\n",
    "test_loaders = get_dataloaders(tokenized_test, num_adapters, split=\"test\")"
   ],
   "id": "845d0b93966bbf02",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3600000/3600000 [03:40<00:00, 16335.35 examples/s]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T19:47:05.656218Z",
     "start_time": "2025-01-08T19:46:58.978512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate both adapters on respective datasets\n",
    "model.eval()\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "for i in range(num_adapters):\n",
    "    total_loss = 0\n",
    "    for batch in test_loaders[i]:\n",
    "        ids, masks, labels, masking = batch\n",
    "        labels = labels.type(torch.float)\n",
    "        o = model(ids.to(device), masks.to(device), masking.to(device))\n",
    "        loss = criterion(torch.squeeze(o), labels.to(device))\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Adapter {i} loss: {total_loss / len(test_loaders[i])}\")"
   ],
   "id": "b8182de951464ffa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter 0 loss: 0.6964581495239621\n",
      "Adapter 1 loss: 0.7075934012730917\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "aa1b010fabc8010c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T19:47:18.435964Z",
     "start_time": "2025-01-08T19:47:05.708928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_datasets = get_tokenized_datasets([\"imdb\", \"fancyzhx/amazon_polarity\"], [tokenize_imdb, tokenize_amazon], num_samples=1000, split=\"train\")\n",
    "\n",
    "train_dataloader = get_dataloaders(tokenized_datasets, num_adapters, split=\"train\")"
   ],
   "id": "73b09760f777e380",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T19:47:18.476620Z",
     "start_time": "2025-01-08T19:47:18.470084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Mark only LoRA parameters as trainable\n",
    "for name, param in model.named_parameters():\n",
    "    if \"adapter\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6, weight_decay=0)  \n",
    "\n",
    "num_epochs = 100\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ],
   "id": "a9ed8f83e593f02a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T19:47:18.527352Z",
     "start_time": "2025-01-08T19:47:18.521187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.requires_grad)"
   ],
   "id": "64aaeb79220553c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.encoder.layer.0.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.0.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.0.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.0.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.0.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.0.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.0.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.0.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.0.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.0.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.0.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.0.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.1.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.1.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.1.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.1.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.1.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.1.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.1.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.1.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.1.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.1.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.1.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.1.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.2.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.2.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.2.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.2.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.2.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.2.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.2.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.2.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.2.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.2.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.2.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.2.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.3.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.3.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.3.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.3.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.3.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.3.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.3.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.3.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.3.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.3.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.3.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.3.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.4.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.4.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.4.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.4.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.4.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.4.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.4.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.4.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.4.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.4.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.4.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.4.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.5.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.5.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.5.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.5.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.5.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.5.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.5.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.5.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.5.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.5.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.5.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.5.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.6.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.6.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.6.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.6.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.6.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.6.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.6.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.6.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.6.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.6.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.6.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.6.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.7.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.7.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.7.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.7.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.7.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.7.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.7.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.7.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.7.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.7.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.7.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.7.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.8.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.8.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.8.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.8.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.8.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.8.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.8.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.8.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.8.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.8.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.8.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.8.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.9.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.9.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.9.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.9.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.9.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.9.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.9.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.9.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.9.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.9.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.9.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.9.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.10.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.10.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.10.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.10.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.10.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.10.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.10.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.10.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.10.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.10.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.10.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.10.attention.self.value.adapters.1.lora_B True\n",
      "bert.encoder.layer.11.attention.self.query.adapters.0.lora_A True\n",
      "bert.encoder.layer.11.attention.self.query.adapters.0.lora_B True\n",
      "bert.encoder.layer.11.attention.self.query.adapters.1.lora_A True\n",
      "bert.encoder.layer.11.attention.self.query.adapters.1.lora_B True\n",
      "bert.encoder.layer.11.attention.self.key.adapters.0.lora_A True\n",
      "bert.encoder.layer.11.attention.self.key.adapters.0.lora_B True\n",
      "bert.encoder.layer.11.attention.self.key.adapters.1.lora_A True\n",
      "bert.encoder.layer.11.attention.self.key.adapters.1.lora_B True\n",
      "bert.encoder.layer.11.attention.self.value.adapters.0.lora_A True\n",
      "bert.encoder.layer.11.attention.self.value.adapters.0.lora_B True\n",
      "bert.encoder.layer.11.attention.self.value.adapters.1.lora_A True\n",
      "bert.encoder.layer.11.attention.self.value.adapters.1.lora_B True\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:09:39.150049Z",
     "start_time": "2025-01-08T19:47:18.567118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in tqdm.tqdm(range(num_epochs), desc=\"Training\"):\n",
    "    for batch in train_dataloader:\n",
    "        ids, masks, labels, masking = batch\n",
    "        labels = labels.type(torch.float)\n",
    "\n",
    "        o = model(ids.to(device), masks.to(device), masking.to(device)) \n",
    "\n",
    "        loss = criterion(torch.squeeze(o), labels.to(device))                  \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()  \n",
    "        optimizer.zero_grad()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        \n",
    "print(f\"Training time: {time.time() - start}\")"
   ],
   "id": "c7d9f0847d3ee7b9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [22:20<00:00, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1340.577546596527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "fd56ff8227d9da28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:09:39.321796Z",
     "start_time": "2025-01-08T20:09:39.317945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenized_test = get_tokenized_datasets([\"imdb\", \"fancyzhx/amazon_polarity\"], [tokenize_imdb, tokenize_amazon], num_samples=1000, split=\"test\")\n",
    "# \n",
    "# test_loaders = get_dataloaders(tokenized_test, num_adapters, split=\"test\")"
   ],
   "id": "88dc603910a93968",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:09:46.217367Z",
     "start_time": "2025-01-08T20:09:39.342648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate both adapters on respective datasets\n",
    "model.eval()\n",
    "\n",
    "for i in range(num_adapters):\n",
    "    total_loss = 0\n",
    "    for batch in test_loaders[i]:\n",
    "        ids, masks, labels, masking = batch\n",
    "        labels = labels.type(torch.float)\n",
    "        o = model(ids.to(device), masks.to(device), masking.to(device))\n",
    "        # o = model(ids.to(device), masks.to(device), torch.tensor(i).to(device))\n",
    "        loss = criterion(torch.squeeze(o), labels.to(device))\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Adapter {i} loss: {total_loss / len(test_loaders[i])}\")"
   ],
   "id": "2a207c2e0e21ea88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter 0 loss: 0.5160008011947549\n",
      "Adapter 1 loss: 0.3231774243925299\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving the model",
   "id": "f179764673983a33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:09:46.238101Z",
     "start_time": "2025-01-08T20:09:46.234036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save the tokenizer and the model in `./test-model/` directory \n",
    "# tokenizer.save_pretrained(\"./test-model/\")\n",
    "# model.save_pretrained(\"./test-model/\", push_to_hub=False)"
   ],
   "id": "c8180afd14c3f9c8",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LoRA model finetuning",
   "id": "ba62b50435faa201"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:18:11.833062Z",
     "start_time": "2025-01-08T20:18:10.392011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_adapters = 2\n",
    "\n",
    "bert_normal = AutoModel.from_pretrained(model_name, device_map=\"auto\")\n",
    "loraBerts = [LoRABert(copy.deepcopy(bert_normal)).to(device) for _ in range(num_adapters)]\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Mark only LoRA parameters as trainable\n",
    "for i in range(num_adapters):\n",
    "    for name, param in loraBerts[i].named_parameters():\n",
    "        if \"lora\" in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False"
   ],
   "id": "4dd2ebc0f50e7ede",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initial evaluation",
   "id": "46d78de3f9d75f9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:18:25.797387Z",
     "start_time": "2025-01-08T20:18:11.841607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_test = get_tokenized_datasets([\"imdb\", \"fancyzhx/amazon_polarity\"], [tokenize_imdb, tokenize_amazon], num_samples=1000, split=\"test\")\n",
    "\n",
    "test_loaders = get_dataloaders(tokenized_test, num_adapters, split=\"test\")\n",
    "\n",
    "for i in range(num_adapters):\n",
    "    loraBerts[i].eval()\n",
    "    total_loss = 0\n",
    "    for batch in test_loaders[i]:\n",
    "        ids, masks, labels, _ = batch\n",
    "        labels = labels.type(torch.float)\n",
    "        o = loraBerts[i](ids.to(device), masks.to(device))\n",
    "        loss = criterion(torch.squeeze(o), labels.to(device))\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Adapter {i} loss: {total_loss / len(test_loaders[i])}\")"
   ],
   "id": "4a7c939eaf8897b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter 0 loss: 0.6954372979345775\n",
      "Adapter 1 loss: 0.6972707093708099\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "7d23dda9ce39883c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:18:33.956805Z",
     "start_time": "2025-01-08T20:18:25.814224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "for i in range(num_adapters):\n",
    "    loraBerts[i].train()\n",
    "    \n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "tokenized_datasets = get_tokenized_datasets([\"imdb\", \"fancyzhx/amazon_polarity\"], [tokenize_imdb, tokenize_amazon], num_samples=1000, split=\"train\")\n",
    "train_dataloaders = get_dataloaders(tokenized_datasets, num_adapters, split=\"test\")\n",
    "\n",
    "num_epochs = 100\n",
    "optimizers = [AdamW(loraBerts[i].parameters(), lr=5e-6, weight_decay=0) for i in range(num_adapters)]\n",
    "num_training_steps = [num_epochs * len(train_dataloaders[i]) for i in range(num_adapters)]\n",
    "lr_schedulers = [get_scheduler(\"linear\", optimizer=optimizers[i], num_warmup_steps=0, num_training_steps=num_training_steps[i]) for i in range(num_adapters)]"
   ],
   "id": "5e7c93db0d7c0407",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:39:28.859797Z",
     "start_time": "2025-01-08T20:18:33.999448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(num_adapters):\n",
    "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "        for batch in train_dataloaders[i]:\n",
    "            ids, masks, labels, _ = batch\n",
    "            labels = labels.type(torch.float)\n",
    "            o = loraBerts[i](ids.to(device), masks.to(device))\n",
    "\n",
    "            loss = criterion(torch.squeeze(o), labels.to(device))\n",
    "            loss.backward()\n",
    "\n",
    "            optimizers[i].step()\n",
    "            optimizers[i].zero_grad()\n",
    "            lr_schedulers[i].step()\n",
    "\n",
    "print(f\"Training time: {time.time() - start}\")"
   ],
   "id": "63b57563e03812a5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:24<00:00,  6.25s/it]\n",
      "100%|██████████| 100/100 [10:30<00:00,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1254.8561878204346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "feb1688690b914f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:39:29.049408Z",
     "start_time": "2025-01-08T20:39:29.046299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenized_test = get_tokenized_datasets([\"imdb\", \"fancyzhx/amazon_polarity\"], [tokenize_imdb, tokenize_amazon], num_samples=1000, split=\"test\")\n",
    "# \n",
    "# test_loaders = get_dataloaders(tokenized_test, num_adapters, split=\"test\")"
   ],
   "id": "22089034730605e5",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:39:34.765560Z",
     "start_time": "2025-01-08T20:39:29.073055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(num_adapters):\n",
    "    loraBerts[i].eval()\n",
    "    total_loss = 0\n",
    "    for batch in test_loaders[i]:\n",
    "        ids, masks, labels, _ = batch\n",
    "        labels = labels.type(torch.float)\n",
    "        o = loraBerts[i](ids.to(device), masks.to(device))\n",
    "        loss = criterion(torch.squeeze(o), labels.to(device))\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Adapter {i} loss: {total_loss / len(test_loaders[i])}\")"
   ],
   "id": "c3244a28ed8d827f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter 0 loss: 0.39156391672671786\n",
      "Adapter 1 loss: 0.26672376987953034\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
